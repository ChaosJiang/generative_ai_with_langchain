{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a731d4b1",
   "metadata": {},
   "source": [
    "# Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b0b87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of input messages: 1\n",
      "History length: 2\n",
      "Amount of input messages: 1\n",
      "History length: 4\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.language_models import FakeListChatModel\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.messages import trim_messages, HumanMessage\n",
    "\n",
    "\n",
    "class PrintOutputCallback(BaseCallbackHandler):\n",
    "    def on_chat_model_start(self, serialized, messages, **kwargs) -> None:\n",
    "        print(f\"Amount of input messages: {len(messages)}\")\n",
    "\n",
    "\n",
    "sessions: dict[str, InMemoryChatMessageHistory] = {}\n",
    "handler = PrintOutputCallback()\n",
    "llm = FakeListChatModel(responses=[\"ai1\", \"ai2\", \"ai3\"])\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in sessions:\n",
    "        sessions[session_id] = InMemoryChatMessageHistory()\n",
    "    return sessions[session_id]\n",
    "\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=1,\n",
    "    strategy=\"last\",\n",
    "    token_counter=len,\n",
    "    include_system=True,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "raw_chain = trimmer | llm\n",
    "chain = RunnableWithMessageHistory(raw_chain, get_session_history)\n",
    "\n",
    "config = {\"callbacks\": [PrintOutputCallback()], \"configurable\": {\"session_id\": \"1\"}}\n",
    "_ = chain.invoke([HumanMessage(\"Hi!\")], config=config)\n",
    "\n",
    "print(f\"History length: {len(sessions['1'].messages)}\")\n",
    "\n",
    "_ = chain.invoke(\n",
    "    [HumanMessage(\"How are you?\")],\n",
    "    config=config,\n",
    ")\n",
    "print(f\"History length: {len(sessions['1'].messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0f875a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ai1', additional_kwargs={}, response_metadata={}, id='run--01d70160-fe9a-475f-ad8e-21d0e9a6f17c-0'),\n",
       " HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ai2', additional_kwargs={}, response_metadata={}, id='run--5ec601ac-7b62-4c9e-8aad-7a47c20a9b33-0')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[\"1\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52818f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(sessions[\"1\"].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c0d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessageGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "def test_node(state):\n",
    "    print(f\"State: {state}\")\n",
    "    print(f\"History length= {len(state[:-1])}\")\n",
    "    return [AIMessage(\"Hello!\")]\n",
    "\n",
    "\n",
    "builder = MessageGraph()\n",
    "builder.add_node(\"test_node\", test_node)\n",
    "builder.add_edge(START, \"test_node\")\n",
    "builder.add_edge(\"test_node\", END)\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81eb61d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: [HumanMessage(content='test', additional_kwargs={}, response_metadata={}, id='5683cd9c-3743-4255-8eb3-aff539229289')]\n",
      "History length= 0\n",
      "State: [HumanMessage(content='test', additional_kwargs={}, response_metadata={}, id='2952015a-3880-4d52-b78d-ba9f844c5b22')]\n",
      "History length= 0\n",
      "State: [HumanMessage(content='test', additional_kwargs={}, response_metadata={}, id='5683cd9c-3743-4255-8eb3-aff539229289'), AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}, id='ceb53564-5dfa-4fcc-8909-18d627e77cc9'), HumanMessage(content='test', additional_kwargs={}, response_metadata={}, id='8ea84a6f-3322-43fc-9676-99eba760caf8')]\n",
      "History length= 2\n"
     ]
    }
   ],
   "source": [
    "_ = graph.invoke(\n",
    "    [HumanMessage(content=\"test\")], config={\"configurable\": {\"thread_id\": \"thread-a\"}}\n",
    ")\n",
    "_ = graph.invoke(\n",
    "    [HumanMessage(content=\"test\")], config={\"configurable\": {\"thread_id\": \"thread-b\"}}\n",
    ")\n",
    "_ = graph.invoke(\n",
    "    [HumanMessage(content=\"test\")], config={\"configurable\": {\"thread_id\": \"thread-a\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f3241dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1f0713b3-cd89-6fac-8004-3cb4f856af77\n",
      "1f0713b3-cd88-6b16-8003-752bc551984e\n",
      "1f0713b3-cd87-6fa4-8002-073e8b0f805a\n",
      "1f0713b3-cd81-6fdc-8001-67e86116a3f6\n",
      "1f0713b3-cd7f-6d36-8000-783310f23100\n",
      "1f0713b3-cd7d-6266-bfff-343143016866\n"
     ]
    }
   ],
   "source": [
    "checkpoints = list(memory.list(config={\"configurable\": {\"thread_id\": \"thread-a\"}}))\n",
    "\n",
    "for check_point in checkpoints:\n",
    "    print(check_point.config[\"configurable\"][\"checkpoint_id\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative_ai_with_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
